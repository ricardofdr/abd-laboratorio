{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aac89911",
   "metadata": {},
   "source": [
    "# PARTE 3 - Treino do modelo, alternativa B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9341c11e",
   "metadata": {},
   "source": [
    "Para este modelo, vai ser usado o dataset criado na parte 2 designado **df_offers_and_trainHistory_with_count.csv.gz** que resulta do join das tabelas trainHistory.csv.gz com offers.csv.gz para cada offer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cc59a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "\n",
    "\n",
    "# Basic imports\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('.env')\n",
    "import os\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import csv\n",
    "import os\n",
    "import datetime\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "from pyspark.sql.functions import col, when, lit, to_date, datediff\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier, LinearSVC, DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "import plotly.express as px\n",
    "import plotly.express as px\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20280322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build SparkSession\n",
    "spark = SparkSession.builder.appName(\"DataPreparation\").getOrCreate()\n",
    "base_path = os.getenv('BASE_PATH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e5dea3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset = spark.read.csv(\n",
    "    f\"{base_path}/improved/df_offers_and_trainHistory.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "df_dataset = df_dataset.withColumn(\"repeater\", F.when(F.col(\"repeater\") == \"t\", 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "888eb704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- offer: integer (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- chain: integer (nullable = true)\n",
      " |-- market: integer (nullable = true)\n",
      " |-- repeattrips: integer (nullable = true)\n",
      " |-- repeater: integer (nullable = false)\n",
      " |-- offerdate: date (nullable = true)\n",
      " |-- category: integer (nullable = true)\n",
      " |-- quantity: integer (nullable = true)\n",
      " |-- company: integer (nullable = true)\n",
      " |-- offervalue: double (nullable = true)\n",
      " |-- brand: integer (nullable = true)\n",
      "\n",
      "+-------+--------+-----+------+-----------+--------+----------+--------+--------+---------+----------+------+\n",
      "|  offer|      id|chain|market|repeattrips|repeater| offerdate|category|quantity|  company|offervalue| brand|\n",
      "+-------+--------+-----+------+-----------+--------+----------+--------+--------+---------+----------+------+\n",
      "|1208251|   86246|  205|    34|          5|       1|2013-04-24|    2202|       1|104460040|       2.0|  3718|\n",
      "|1197502|   86252|  205|    34|         16|       1|2013-03-27|    3203|       1|106414464|      0.75| 13474|\n",
      "|1197502|12682470|   18|    11|          0|       0|2013-03-28|    3203|       1|106414464|      0.75| 13474|\n",
      "|1197502|12996040|   15|     9|          0|       0|2013-03-25|    3203|       1|106414464|      0.75| 13474|\n",
      "|1204821|13089312|   15|     9|          0|       0|2013-04-01|    5619|       1|107717272|       1.5|102504|\n",
      "+-------+--------+-----+------+-----------+--------+----------+--------+--------+---------+----------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dataset.printSchema()\n",
    "df_dataset.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185a2c99",
   "metadata": {},
   "source": [
    "Tendo em conta o schema acima do dataset, as features escolhidas foram as:\n",
    "- **offervalue** -> valor binário com o valor da oferta.\n",
    "- **category** -> category of the made offer\n",
    "- **quantity** -> quantity of the made offer\n",
    "- **brand** -> brand of the made offer\n",
    "- **company** -> company that the offer originates from."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90941e5d",
   "metadata": {},
   "source": [
    "Bellow we exclude and identify the columns that were not chosen as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adc523c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 127878 rows in the training set and 32179 rows in the validation set.\n"
     ]
    }
   ],
   "source": [
    "df_train, df_validation = df_dataset.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(f'There are {df_train.count()} rows in the training set and {df_validation.count()} rows in the validation set.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e4dc3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_feature = ['offervalue', 'category', 'quantity', 'brand', 'company']\n",
    "\n",
    "vec_assembler = VectorAssembler(\n",
    "    inputCols=cols_feature,\n",
    "    outputCol='features'\n",
    ")\n",
    "\n",
    "train_assembled = vec_assembler.transform(df_train)\n",
    "validation_assembled = vec_assembler.transform(df_validation)\n",
    "\n",
    "modelos = {\n",
    "    \"LogisticRegression\": LogisticRegression(labelCol=\"repeater\", featuresCol=\"features\"),\n",
    "    \"RandomForest\":  RandomForestClassifier(labelCol=\"repeater\", featuresCol=\"features\"),\n",
    "    \"GradientBoosting\": GBTClassifier(labelCol=\"repeater\", featuresCol=\"features\"),\n",
    "    \"LinearSVC\": LinearSVC(labelCol=\"repeater\", featuresCol=\"features\"),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(labelCol=\"repeater\", featuresCol=\"features\")\n",
    "}\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"repeater\", metricName=\"areaUnderROC\")\n",
    "results = {}\n",
    "detailed_results = {}\n",
    "\n",
    "def calculate_metrics(predictions):\n",
    "    \"\"\"Calculate detailed classification metrics from predictions\"\"\"\n",
    "    # Get confusion matrix components\n",
    "    confusion_matrix = predictions.groupBy('repeater', 'prediction').count()\n",
    "\n",
    "    tp = confusion_matrix.filter((confusion_matrix.repeater == 1) & (confusion_matrix.prediction == 1)).select('count').first()\n",
    "    tn = confusion_matrix.filter((confusion_matrix.repeater == 0) & (confusion_matrix.prediction == 0)).select('count').first()\n",
    "    fp = confusion_matrix.filter((confusion_matrix.repeater == 0) & (confusion_matrix.prediction == 1)).select('count').first()\n",
    "    fn = confusion_matrix.filter((confusion_matrix.repeater == 1) & (confusion_matrix.prediction == 0)).select('count').first()\n",
    "\n",
    "    # Handle None values (when category doesn't exist)\n",
    "    tp_val = tp['count'] if tp else 0\n",
    "    tn_val = tn['count'] if tn else 0\n",
    "    fp_val = fp['count'] if fp else 0\n",
    "    fn_val = fn['count'] if fn else 0\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = (tp_val + tn_val) / (tp_val + tn_val + fp_val + fn_val) if (tp_val + tn_val + fp_val + fn_val) > 0 else 0\n",
    "    precision = tp_val / (tp_val + fp_val) if (tp_val + fp_val) > 0 else 0\n",
    "    recall = tp_val / (tp_val + fn_val) if (tp_val + fn_val) > 0 else 0\n",
    "    specificity = tn_val / (tn_val + fp_val) if (tn_val + fp_val) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'specificity': specificity,\n",
    "        'f1_score': f1_score,\n",
    "        'confusion_matrix': {'TP': tp_val, 'TN': tn_val, 'FP': fp_val, 'FN': fn_val}\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0c03c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training LogisticRegression...\n",
      "==================================================\n",
      "LogisticRegression AUC-ROC: 0.5730\n",
      "LogisticRegression Accuracy: 0.7289\n",
      "LogisticRegression Precision: 0.0000\n",
      "LogisticRegression Recall: 0.0000\n",
      "LogisticRegression Specificity: 1.0000\n",
      "LogisticRegression F1 Score: 0.0000\n",
      "\n",
      "==================================================\n",
      "Training RandomForest...\n",
      "==================================================\n",
      "RandomForest AUC-ROC: 0.6472\n",
      "RandomForest Accuracy: 0.7289\n",
      "RandomForest Precision: 0.0000\n",
      "RandomForest Recall: 0.0000\n",
      "RandomForest Specificity: 1.0000\n",
      "RandomForest F1 Score: 0.0000\n",
      "\n",
      "==================================================\n",
      "Training GradientBoosting...\n",
      "==================================================\n",
      "GradientBoosting AUC-ROC: 0.6760\n",
      "GradientBoosting Accuracy: 0.7299\n",
      "GradientBoosting Precision: 0.5123\n",
      "GradientBoosting Recall: 0.0763\n",
      "GradientBoosting Specificity: 0.9730\n",
      "GradientBoosting F1 Score: 0.1329\n",
      "\n",
      "==================================================\n",
      "Training LinearSVC...\n",
      "==================================================\n",
      "LinearSVC AUC-ROC: 0.5190\n",
      "LinearSVC Accuracy: 0.7289\n",
      "LinearSVC Precision: 0.0000\n",
      "LinearSVC Recall: 0.0000\n",
      "LinearSVC Specificity: 1.0000\n",
      "LinearSVC F1 Score: 0.0000\n",
      "\n",
      "==================================================\n",
      "Training DecisionTree...\n",
      "==================================================\n",
      "DecisionTree AUC-ROC: 0.3829\n",
      "DecisionTree Accuracy: 0.7299\n",
      "DecisionTree Precision: 0.5123\n",
      "DecisionTree Recall: 0.0763\n",
      "DecisionTree Specificity: 0.9730\n",
      "DecisionTree F1 Score: 0.1329\n",
      "Melhor modelo: GradientBoosting com AUC-ROC 0.6759872730209203\n"
     ]
    }
   ],
   "source": [
    "for nome, modelo in modelos.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training {nome}...\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Configurar validação cruzada\n",
    "    paramGrid = ParamGridBuilder().build()\n",
    "    if nome == \"RandomForest\":\n",
    "        paramGrid = ParamGridBuilder() \\\n",
    "            .addGrid(modelo.numTrees, [50]) \\\n",
    "            .addGrid(modelo.maxDepth, [10]) \\\n",
    "            .addGrid(modelo.seed, [42]) \\\n",
    "            .build()\n",
    "    elif nome == \"GradientBoosting\":\n",
    "        paramGrid = ParamGridBuilder() \\\n",
    "            .addGrid(modelo.maxIter, [50]) \\\n",
    "            .addGrid(modelo.maxDepth, [5]) \\\n",
    "            .addGrid(modelo.seed, [42]) \\\n",
    "            .build()\n",
    "    elif nome == \"LinearSVC\":\n",
    "        paramGrid = ParamGridBuilder() \\\n",
    "            .addGrid(modelo.maxIter, [100]) \\\n",
    "            .addGrid(modelo.regParam, [0.1]) \\\n",
    "            .build()\n",
    "    elif nome == \"DecisionTree\":\n",
    "        paramGrid = ParamGridBuilder() \\\n",
    "            .addGrid(modelo.maxDepth, [10]) \\\n",
    "            .addGrid(modelo.seed, [42]) \\\n",
    "            .build()\n",
    "    elif nome == \"LogisticRegression\":\n",
    "        paramGrid = ParamGridBuilder() \\\n",
    "            .addGrid(modelo.maxIter, [100]) \\\n",
    "            .addGrid(modelo.regParam, [0.1]) \\\n",
    "            .build()\n",
    "\n",
    "    crossval = CrossValidator(\n",
    "        estimator=modelo,\n",
    "        estimatorParamMaps=paramGrid,\n",
    "        evaluator=evaluator,\n",
    "        numFolds=3\n",
    "    )\n",
    "    \n",
    "    # Treinar modelo\n",
    "    cv_model = crossval.fit(train_assembled)\n",
    "    cv_model.save(f\"modelos/{nome}\")\n",
    "\n",
    "    # Avaliar na validação\n",
    "    predictions = cv_model.transform(validation_assembled)\n",
    "    auc = evaluator.evaluate(predictions)\n",
    "    results[nome] = auc\n",
    "    \n",
    "    metrics = calculate_metrics(predictions)\n",
    "    detailed_results[nome] = {**metrics, 'auc_roc': auc}\n",
    "\n",
    "\n",
    "    print(f\"{nome} AUC-ROC: {auc:.4f}\")\n",
    "    print(f\"{nome} Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    print(f\"{nome} Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"{nome} Recall: {metrics['recall']:.4f}\")\n",
    "    print(f\"{nome} Specificity: {metrics['specificity']:.4f}\")\n",
    "    print(f\"{nome} F1 Score: {metrics['f1_score']:.4f}\")\n",
    "\n",
    "melhor_modelo_nome = max(results, key=results.get)\n",
    "print(f\"Melhor modelo: {melhor_modelo_nome} com AUC-ROC {results[melhor_modelo_nome]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dd32fa",
   "metadata": {},
   "source": [
    "What These Results Mean:\n",
    "Precision = 1.0 & Specificity = 1.0\n",
    "Your model is extremely conservative - when it predicts someone is a repeater, it's always right\n",
    "It correctly identifies 100% of non-repeaters\n",
    "BUT this suggests the model rarely predicts positive cases\n",
    "Recall = 0.013 (1.3%)\n",
    "Your model is missing 98.7% of actual repeaters\n",
    "It's only catching about 1 in 77 real repeat customers\n",
    "F1 Score = 0.026 (2.6%)\n",
    "This very low score confirms the model is practically useless for finding repeaters\n",
    "Root Cause Analysis:\n",
    "This pattern typically indicates:\n",
    "\n",
    "Severe Class Imbalance: You likely have very few repeaters (positive cases) in your dataset\n",
    "Conservative Model: The model learned to almost always predict \"not a repeater\" to maximize accuracy\n",
    "Feature Issues: The features may not be discriminative enough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa545f04",
   "metadata": {},
   "source": [
    "LSVC and Random Forest Results:\n",
    "Precision = 0, Recall = 0, F1 = 0: These models predict ZERO repeaters - they classify everyone as non-repeaters\n",
    "Specificity = 1.0: Perfect at identifying non-repeaters (because they never predict repeaters)\n",
    "Accuracy ≈ 0.729: This just reflects your class distribution - about 73% of your data are non-repeaters\n",
    "GBT (Gradient Boosted Trees) Results:\n",
    "Precision = 0.512: When it predicts someone is a repeater, it's right about 51% of the time\n",
    "Recall = 0.076: It only catches 7.6% of actual repeaters\n",
    "F1 = 0.133: Still poor overall performance, but at least it's trying to predict some repeaters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ff942a",
   "metadata": {},
   "source": [
    "Acho que o problema é que estamos a tentar prever compradores apenas com base no historico de ofertas e ofertas que levaram a comprar novamente e as\n",
    "suas caracteristicas o que pode nao ser suficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca9a000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract model names and AUC-ROC scores from the results list\n",
    "# Replace these placeholder AUC-ROC values with actual values from your results\n",
    "results_data = [\n",
    "    (\"RandomForest\", 0.85, None),  # Example AUC-ROC value\n",
    "    (\"LogisticRegression\", 0.80, None),  # Example AUC-ROC value\n",
    "    (\"DecisionTree\", 0.75, None),  # Example AUC-ROC value\n",
    "    (\"GradientBoostedTrees\", 0.88, None),  # Example AUC-ROC value\n",
    "    (\"LinearSVC\", 0.82, None)  # Example AUC-ROC value (replace with your linear_svc_auc_roc)\n",
    "]\n",
    "\n",
    "# Create a DataFrame for Plotly\n",
    "data = {\n",
    "    \"Model\": [name for name, _, _ in results_data],\n",
    "    \"AUC-ROC\": [auc for _, auc, _ in results_data]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create a bar chart using Plotly Express\n",
    "fig = px.bar(\n",
    "    df,\n",
    "    x=\"Model\",\n",
    "    y=\"AUC-ROC\",\n",
    "    title=\"Comparison of Model Performance (AUC-ROC)\",\n",
    "    labels={\"AUC-ROC\": \"AUC-ROC Score\", \"Model\": \"Model Name\"},\n",
    "    color=\"Model\",\n",
    "    color_discrete_sequence=px.colors.qualitative.Plotly\n",
    ")\n",
    "\n",
    "# Update layout for better readability\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Model\",\n",
    "    yaxis_title=\"AUC-ROC Score\",\n",
    "    yaxis_range=[0, 1],  # AUC-ROC scores are typically between 0 and 1\n",
    "    showlegend=False,\n",
    "    title_x=0.5\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode_pyspark",
   "language": "python",
   "name": "vscode_pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
