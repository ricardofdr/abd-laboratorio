{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb9dbb25",
   "metadata": {},
   "source": [
    "# 1. Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee68e411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('.env')\n",
    "import os\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e06ac47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build SparkSession\n",
    "spark = SparkSession.builder.appName(\"DataPreparation\").getOrCreate()\n",
    "base_path = os.getenv('BASE_PATH')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1fb34b",
   "metadata": {},
   "source": [
    "## Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46511308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to read - offers.csv\n",
    "data_dir_offers = f'{base_path}/offers.csv.gz'\n",
    "data_file_offers = data_dir_offers\n",
    "\n",
    "! head $data_file_offers\n",
    "\n",
    "# Data to read - sampleSubmission.csv\n",
    "data_dir_sampleSubmission = f'{base_path}/sampleSubmission.csv.gz'\n",
    "data_file_sampleSubmission = data_dir_sampleSubmission\n",
    "\n",
    "! head $data_file_sampleSubmission\n",
    "\n",
    "# Data to read - testHistory.csv\n",
    "data_dir_testHistory = f'{base_path}/testHistory.csv.gz'\n",
    "data_file_testHistory = data_dir_testHistory\n",
    "\n",
    "! head $data_file_testHistory\n",
    "\n",
    "# Data to read - trainHistory.csv\n",
    "data_dir_trainHistory = f'{base_path}/trainHistory.csv.gz'\n",
    "data_file_trainHistory = data_dir_trainHistory\n",
    "\n",
    "! head $data_file_trainHistory\n",
    "\n",
    "# Data to read - transactions.csv\n",
    "data_dir_transactions = f'{base_path}/transactions.csv.gz'\n",
    "data_file_transactions = data_dir_transactions\n",
    "\n",
    "! head $data_file_transactions;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b477ea5",
   "metadata": {},
   "source": [
    "OFFERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4a6c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data - offers.csv\n",
    "df_offers = spark.read.csv(\n",
    "        data_file_offers, \n",
    "        header=True, sep=',', inferSchema=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94cda9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking data that has been read - testHistory.csv\n",
    "print(f'df_offers - number of rows: {df_offers.count()}')\n",
    "df_offers.printSchema()\n",
    "df_offers.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275942cd",
   "metadata": {},
   "source": [
    "TESTHISTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebed89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data - testHistory.csv\n",
    "df_testHistory = spark.read.csv(\n",
    "        data_file_testHistory, \n",
    "        header=True, sep=',', inferSchema=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6205c176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking data that has been read - testHistory.csv\n",
    "print(f'df_testHistory - number of rows: {df_testHistory.count()}')\n",
    "df_testHistory.printSchema()\n",
    "df_testHistory.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0878f730",
   "metadata": {},
   "source": [
    "TRAINHISTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378419e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data - trainHistory.csv\n",
    "df_trainHistory = spark.read.csv(\n",
    "        data_file_trainHistory, \n",
    "        header=True, sep=',', inferSchema=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03a84a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking data that has been read - trainHistory.csv\n",
    "print(f'df_trainHistory - number of rows: {df_trainHistory.count()}')\n",
    "df_trainHistory.printSchema()\n",
    "df_trainHistory.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404ef6fe",
   "metadata": {},
   "source": [
    "TRANSACTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af3c113",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactions = spark.read.csv(\n",
    "    data_file_transactions, \n",
    "    header=True, sep=',', inferSchema=True\n",
    ").sample(fraction=0.001, seed=42).limit(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28e512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking a sample of the transactions data\n",
    "print(f'df_transactions - number of rows: {df_transactions.count()}')\n",
    "df_transactions.printSchema()\n",
    "df_transactions.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef91895c",
   "metadata": {},
   "source": [
    "## Data Validation and Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f2cff5",
   "metadata": {},
   "source": [
    "**Checking for duplicates and nulls**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40aa09f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'df_offers - number of rows is {df_offers.count()}; after dropDuplicates() applied would be {df_offers.dropDuplicates().count()}.')                                  # offers.csv\n",
    "print(f'df_testHistory - number of rows is {df_testHistory.count()}; after dropDuplicates() applied would be {df_testHistory.dropDuplicates().count()}.')                   # testHistory.csv\n",
    "print(f'df_trainHistory - number of rows is {df_trainHistory.count()}; after dropDuplicates() applied would be {df_trainHistory.dropDuplicates().count()}.')                # trainHistory.csv\n",
    "print(f'df_transactions - number of rows is {df_transactions.count()}; after dropDuplicates() applied would be {df_transactions.dropDuplicates().count()}.')                # transactions.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990b715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'''df_offers - number of rows after dropna(how='any') applied would be {df_offers.dropna(how='any').count()}.''')                        # offers.csv\n",
    "print(f'''df_testHistory - number of rows after dropna(how='any') applied would be {df_testHistory.dropna(how='any').count()}.''')              # testHistory.csv\n",
    "print(f'''df_trainHistory - number of rows after dropna(how='any') applied would be {df_trainHistory.dropna(how='any').count()}.''')            # trainHistory.csv\n",
    "print(f'''df_transactions - number of rows after dropna(how='any') applied would be {df_transactions.dropna(how='any').count()}.''')            # transactions.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbc5b83",
   "metadata": {},
   "source": [
    "**Generating Html files with full report for each data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8568c6fb",
   "metadata": {},
   "source": [
    "OFFERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904c623b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# offers.csv\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "profile_title_offers = 'offers.csv'\n",
    "\n",
    "profile_report = ProfileReport(\n",
    "    df_offers,\n",
    "    title=profile_title_offers,\n",
    "    infer_dtypes=False,\n",
    "    interactions=None,\n",
    "    missing_diagrams=None,\n",
    "    correlations={\n",
    "        \"auto\": {\"calculate\": False},\n",
    "        \"pearson\": {\"calculate\": False},\n",
    "        \"spearman\": {\"calculate\": False},\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f161c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# offers.csv\n",
    "profile_report_file = data_dir_offers + 'profile-' + profile_title_offers + '.html'\n",
    "profile_report.to_file(Path(profile_report_file))\n",
    "profile_report_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac7c4c7",
   "metadata": {},
   "source": [
    "TESTHISTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cc4275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testHistory.csv\n",
    "profile_title_testHistory = 'testHistory.csv'\n",
    "\n",
    "profile_report = ProfileReport(\n",
    "    df_testHistory.toPandas(),\n",
    "    title=profile_title_testHistory,\n",
    "    infer_dtypes=False,\n",
    "    interactions=None,\n",
    "    missing_diagrams=None,\n",
    "    correlations={\n",
    "        \"auto\": {\"calculate\": False},\n",
    "        \"pearson\": {\"calculate\": False},\n",
    "        \"spearman\": {\"calculate\": False},\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbec241c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testHistory.csv\n",
    "profile_report_file = data_dir_testHistory + 'profile-' + profile_title_testHistory + '.html'\n",
    "profile_report.to_file(Path(profile_report_file))\n",
    "profile_report_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97ccf63",
   "metadata": {},
   "source": [
    "TRAINHISTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a88ab14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainHistory.csv\n",
    "profile_title_trainHistory = 'trainHistory.csv'\n",
    "\n",
    "profile_report = ProfileReport(\n",
    "    df_trainHistory.toPandas(),\n",
    "    title=profile_title_trainHistory,\n",
    "    infer_dtypes=False,\n",
    "    interactions=None,\n",
    "    missing_diagrams=None,\n",
    "    correlations={\n",
    "        \"auto\": {\"calculate\": False},\n",
    "        \"pearson\": {\"calculate\": False},\n",
    "        \"spearman\": {\"calculate\": False},\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44be427d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainHistory.csv\n",
    "profile_report_file = data_dir_trainHistory + 'profile-' + profile_title_trainHistory + '.html'\n",
    "profile_report.to_file(Path(profile_report_file))\n",
    "profile_report_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da3d871",
   "metadata": {},
   "source": [
    "TRANSACTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c832ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transactions.csv\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "profile_title_transactions = 'transactions.csv'\n",
    "\n",
    "profile_report = ProfileReport(\n",
    "    df_transactions.toPandas(),\n",
    "    title=profile_title_transactions,\n",
    "    infer_dtypes=False,\n",
    "    interactions=None,\n",
    "    missing_diagrams=None,\n",
    "    correlations={\n",
    "        \"auto\": {\"calculate\": False},\n",
    "        \"pearson\": {\"calculate\": False},\n",
    "        \"spearman\": {\"calculate\": False},\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111ebf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transactions.csv\n",
    "profile_report_file = data_dir_transactions + 'profile-' + profile_title_transactions + '.html'\n",
    "profile_report.to_file(Path(profile_report_file))\n",
    "profile_report_file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode_pyspark",
   "language": "python",
   "name": "vscode_pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
