{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aac89911",
   "metadata": {},
   "source": [
    "# PARTE 3 - Treino do modelo, alternativa B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9341c11e",
   "metadata": {},
   "source": [
    "Para este modelo, vai ser usado o dataset criado na parte 2 designado **df_corr_category_and_category_success.csv.gz** que resulta do join das tabelas trainHistory.csv.gz com offers.csv.gz para cada offer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8cc59a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('.env')\n",
    "import os\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import VectorAssembler, OneHotEncoder\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20280322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build SparkSession\n",
    "spark = SparkSession.builder.appName(\"DataPreparation\").getOrCreate()\n",
    "base_path = os.getenv('BASE_PATH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e5dea3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset = spark.read.csv(\n",
    "    f\"{base_path}-ml/df_corr_category_and_category_success.csv.gz\",\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "888eb704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- offer: integer (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- chain: integer (nullable = true)\n",
      " |-- market: integer (nullable = true)\n",
      " |-- repeattrips: integer (nullable = true)\n",
      " |-- repeater: integer (nullable = true)\n",
      " |-- offerdate: date (nullable = true)\n",
      " |-- category: integer (nullable = true)\n",
      " |-- quantity: integer (nullable = true)\n",
      " |-- company: integer (nullable = true)\n",
      " |-- offervalue: double (nullable = true)\n",
      " |-- brand: integer (nullable = true)\n",
      " |-- offer_count: integer (nullable = true)\n",
      " |-- offer_success_percentage: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dataset.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185a2c99",
   "metadata": {},
   "source": [
    "Tendo em conta o schema acima do dataset, as features escolhidas foram as:\n",
    "- **repeattrips** -> valor númerico que diz o número de vezes que o cliente voltou a comprar a oferta\n",
    "- **repeater** -> valor binário onde 1 representa um cliente voltar a comprar a oferta e 0 representa o cliente não voltar a comprar a oferta.\n",
    "- **offervalue** -> valor binário com o valor da oferta.\n",
    "- **offer_count** -> número de vezes que a oferta foi feita.\n",
    "- **offer_success_percentage** -> probabilidade de successo da oferta.\n",
    "- **category** -> category of the made offer\n",
    "- **quantity** -> quantity of the made offer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90941e5d",
   "metadata": {},
   "source": [
    "Bellow we exclude and identify the columns that were not chosen as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e4dc3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols_not_feature = ['id', 'chain', 'market', 'offerdate', 'quantity', 'company', 'brand', 'offer']\n",
    "cols_feature = ['repeattrips', 'repeater', 'offervalue', 'offer_count', 'offer_success_percentage', 'category', 'quantity']\n",
    "\n",
    "# # As all the columns are numerical we won't need the StringIndexer\n",
    "# index_output_cols = [x + ' Index' for x in df_dataset.columns if x not in cols_not_feature]\n",
    "# one_output_cols = [x + ' OHE' for x in df_dataset.columns if x not in cols_not_feature]\n",
    "\n",
    "# ohe_encoder = OneHotEncoder(inputCols=one_output_cols, outputCols=one_output_cols)\n",
    "vec_assembler = VectorAssembler(\n",
    "    inputCols=cols_feature,\n",
    "    outputCol='features'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16cc8b4",
   "metadata": {},
   "source": [
    "**Treino do modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ff23afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 127878 rows in the training set and 32179 rows in the validation set.\n"
     ]
    }
   ],
   "source": [
    "df_train, df_validation = df_dataset.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "df_train.write.mode('overwrite').option('header', 'true').option('compression', 'gzip').csv(f\"{base_path}-ml/model_B/df_train.csv.gz\")\n",
    "\n",
    "print(f'There are {df_train.count()} rows in the training set and {df_validation.count()} rows in the validation set.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f103ab47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.write.mode('overwrite').parquet(f\"{base_path}-ml/model_B/df_train.parquet\")\n",
    "df_validation.write.mode('overwrite').parquet(f\"{base_path}-ml/model_B/df_validation.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "52dc4468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVC algorithm\n",
    "lsvc = LinearSVC(maxIter=10, regParam=0.1, labelCol='repeater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed2afcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[vec_assembler, lsvc])\n",
    "\n",
    "pipeline.save('data-ml/model_B/pipeline_model_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "082e1b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save in the pipeline for further use, should it be required\n",
    "pipeline.save('data-ml/model_B/pipeline-LinearSVM-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3ab79327",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e43c5b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model for further use, should it be required.\n",
    "model.save('data-ml/model_B/model-LinearSVM-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b19f892",
   "metadata": {},
   "source": [
    "**Model evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "29860179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- offer: integer (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- chain: integer (nullable = true)\n",
      " |-- market: integer (nullable = true)\n",
      " |-- repeattrips: integer (nullable = true)\n",
      " |-- repeater: integer (nullable = true)\n",
      " |-- offerdate: date (nullable = true)\n",
      " |-- category: integer (nullable = true)\n",
      " |-- quantity: integer (nullable = true)\n",
      " |-- company: integer (nullable = true)\n",
      " |-- offervalue: double (nullable = true)\n",
      " |-- brand: integer (nullable = true)\n",
      " |-- offer_count: integer (nullable = true)\n",
      " |-- offer_success_percentage: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_predictions = model.transform(df_validation)\n",
    "\n",
    "df_predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5c1d6cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under ROC: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32179"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions_eval = df_predictions.select('features', 'rawPrediction', 'prediction', 'repeater')\n",
    "\n",
    "binary_evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol='repeater',\n",
    "    rawPredictionCol='rawPrediction',\n",
    "    metricName='areaUnderROC'\n",
    ")\n",
    "\n",
    "area_under_roc = binary_evaluator.evaluate(df_predictions_eval)\n",
    "\n",
    "print(f\"Area Under ROC: {area_under_roc}\")\n",
    "df_predictions_eval.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f3ae9c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----+\n",
      "|repeater|prediction|count|\n",
      "+--------+----------+-----+\n",
      "|       0|       0.0|23454|\n",
      "|       1|       1.0| 8725|\n",
      "+--------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_confusion_matrix = df_predictions_eval.groupBy('repeater', 'prediction').count()\n",
    "df_confusion_matrix.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a3ee9ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: {'TP': 8725, 'TN': 23454, 'FP': 0, 'FN': 0}\n"
     ]
    }
   ],
   "source": [
    "# Compute the confusion matrix\n",
    "tp = df_confusion_matrix.filter((df_confusion_matrix.repeater == 1) & (df_confusion_matrix.prediction == 1)).select('count').first()\n",
    "tn = df_confusion_matrix.filter((df_confusion_matrix.repeater == 0) & (df_confusion_matrix.prediction == 0)).select('count').first()\n",
    "fp = df_confusion_matrix.filter((df_confusion_matrix.repeater == 0) & (df_confusion_matrix.prediction == 1)).select('count').first()\n",
    "fn = df_confusion_matrix.filter((df_confusion_matrix.repeater == 1) & (df_confusion_matrix.prediction == 0)).select('count').first()\n",
    "\n",
    "confmat = {'TP': 0, 'TN': 0, 'FP': 0, 'FN': 0}\n",
    "\n",
    "if (tp):\n",
    "    confmat['TP'] = tp['count'] * 1\n",
    "if (tn):\n",
    "    confmat['TN'] = tn['count'] * 1\n",
    "if (fp):    \n",
    "    confmat['FP'] = fp['count'] * 1\n",
    "if (fn):\n",
    "    confmat['FN'] = fn['count'] * 1\n",
    "    \n",
    "print(f\"Confusion Matrix: {confmat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f7d3978a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "Specificity: 1.0\n",
      "F1 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "accuracy = (confmat['TP'] + confmat['TN']) / (confmat['TP'] + confmat['TN'] + confmat['FP'] + confmat['FN'])\n",
    "precision = (confmat['TP']) / (confmat['TP'] + confmat['FP']) if (confmat['TP'] + confmat['FP']) > 0 else 0\n",
    "recall = confmat['TP'] / (confmat['TP'] + confmat['FN']) if (confmat['TP'] + confmat['FN']) > 0 else 0\n",
    "specificity = confmat['TN'] / (confmat['TN'] + confmat['FP']) if (confmat['TN'] + confmat['FP']) > 0 else 0\n",
    "fiscore = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Specificity: {specificity}\")\n",
    "print(f\"F1 Score: {fiscore}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode_pyspark",
   "language": "python",
   "name": "vscode_pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
